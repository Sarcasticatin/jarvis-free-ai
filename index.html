<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Jarvis ‚Äî Free (WebLLM)</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    :root {
      --bg: #0b1220; --card: #121a2b; --muted: #6e7b8f;
      --accent: #4f8cff; --text: #e9eef7; --me: #1e2a44; --bot: #0f1a2e;
    }
    * { box-sizing: border-box; }
    body { margin: 0; font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Arial;
           background: radial-gradient(1200px 600px at 70% -10%, #182138, transparent) var(--bg);
           color: var(--text); height: 100vh; display: grid; place-items: center; }
    .app { width: min(100%, 900px); height: min(96vh, 880px); display: grid; grid-template-rows: auto 1fr auto; gap: 10px; }
    header { display: flex; align-items: center; justify-content: space-between; padding: 14px 16px; background: var(--card); border-radius: 14px; }
    header h1 { font-size: 18px; margin: 0; letter-spacing: .3px; }
    header .small { color: var(--muted); font-size: 12px; }
    #chat { background: var(--card); border-radius: 14px; padding: 12px; overflow: auto; }
    .msg { display: grid; gap: 6px; margin: 10px 0; }
    .bubble { padding: 12px 14px; border-radius: 12px; line-height: 1.45; white-space: pre-wrap; }
    .me .bubble { background: var(--me); }
    .bot .bubble { background: var(--bot); border: 1px solid #1c2a44; }
    form { display: grid; grid-template-columns: 1fr auto; gap: 10px; align-items: end; }
    textarea { width: 100%; min-height: 56px; max-height: 180px; resize: vertical;
               padding: 12px 14px; border-radius: 12px; border: 1px solid #223352; background: #0a1324; color: var(--text); }
    button { background: var(--accent); border: 0; color: white; padding: 12px 16px; border-radius: 12px; font-weight: 600; cursor: pointer; }
    .toolbar { display: flex; gap: 8px; align-items: center; }
    .row { display: flex; gap: 10px; align-items: center; }
    .footer { color: var(--muted); font-size: 11px; text-align: center; }
    .hidden { display: none; }
    .pulse { width: 8px; height: 8px; background: var(--accent); border-radius: 50%; box-shadow: 0 0 0 0 rgba(79,140,255,.7); animation: ping 1.2s infinite; }
    @keyframes ping { 0% { box-shadow:0 0 0 0 rgba(79,140,255,.6);} 70% { box-shadow:0 0 0 12px rgba(79,140,255,0);} 100%{ box-shadow:0 0 0 0 rgba(79,140,255,0);} }
  </style>
</head>
<body>
  <div class="app">
    <header>
      <div>
        <h1>Jarvis <span class="small">¬∑ browser‚Äëonly</span></h1>
        <div class="small">Runs locally with WebGPU. No API key. ‚úîÔ∏è</div>
      </div>
      <div class="toolbar">
        <div id="status" class="small">checking WebGPU‚Ä¶</div>
        <div id="dot" class="pulse hidden" title="working"></div>
      </div>
    </header>

    <main id="chat" aria-live="polite"></main>

    <form id="composer">
      <textarea id="input" placeholder="Ask me anything‚Ä¶" autofocus></textarea>
      <button id="send" type="submit">Send</button>
    </form>

    <div class="footer">Powered by <span title="Machine Learning Compilation">WebLLM</span>. Models load once and cache in your browser.</div>
  </div>

  <script type="module">
    import { CreateWebWorkerMLCEngine } from "https://esm.run/@mlc-ai/web-llm";

    const chatEl = document.getElementById('chat');
    const statusEl = document.getElementById('status');
    const dot = document.getElementById('dot');
    const form = document.getElementById('composer');
    const input = document.getElementById('input');

    // Offer two model options: small (faster to load) and medium (better quality).
    const models = {
      "Phi-3-mini-4k-instruct-q4f16_1-MLC": { label: "Phi‚Äë3 mini (smaller)", model_id: "HF://mlc-ai/Phi-3-mini-4k-instruct-q4f16_1-MLC" },
      "Llama-3-8B-Instruct-q4f16_1-MLC":   { label: "Llama3 8B (better)",    model_id: "HF://mlc-ai/Llama-3-8B-Instruct-q4f16_1-MLC" }
    };

    // UI: model selector (no frameworks!)
    const sel = document.createElement('select');
    for (const key of Object.keys(models)) {
      const opt = document.createElement('option');
      opt.value = key;
      opt.textContent = models[key].label;
      sel.appendChild(opt);
    }
    sel.value = "Phi-3-mini-4k-instruct-q4f16_1-MLC"; // default to smaller model
    const label = document.createElement('div');
    label.className = 'small';
    label.textContent = 'Model:';
    const row = document.createElement('div');
    row.className = 'row';
    row.append(label, sel);
    document.querySelector('header').appendChild(row);

    let engine = null;
    let history = []; // {role: 'user'|'assistant', content: string}

    function add(role, text) {
      const div = document.createElement('div');
      div.className = `msg ${role === 'user' ? 'me' : 'bot'}`;
      div.innerHTML = `<div class="bubble">${escape(text)}</div>`;
      chatEl.appendChild(div);
      chatEl.scrollTop = chatEl.scrollHeight;
    }
    function escape(s) { return s.replace(/[&<>"']/g, c => ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#39;'}[c])); }

    function setBusy(busy) {
      statusEl.textContent = busy ? 'thinking‚Ä¶' : statusEl.textContent;
      dot.classList.toggle('hidden', !busy);
    }

    // Load a model (first run downloads weights, then cached)
    async function loadModel(name) {
      statusEl.textContent = "loading model‚Ä¶ (first run downloads files)";
      dot.classList.remove('hidden');
      try {
        engine?.terminate?.();
        const spec = { model_id: models[name].model_id };
        engine = await CreateWebWorkerMLCEngine(
          new Worker("https://esm.run/@mlc-ai/web-llm/dist/worker.js", { type: "module" }),
          spec,
          { logLevel: "info" }
        );
        statusEl.textContent = `ready: ${models[name].label}`;
        if (history.length === 0) add('assistant', "Hi! I'm Jarvis (free & local). Ask me anything. üí°");
      } catch (e) {
        console.error(e);
        add('assistant', "‚ö†Ô∏è WebGPU or model load failed. Try Chrome/Edge desktop, or switch to the smaller model.");
        statusEl.textContent = "error";
      } finally {
        dot.classList.add('hidden');
      }
    }

    // Check WebGPU
    if (!('gpu' in navigator)) {
      statusEl.textContent = "WebGPU not available. Use Chrome/Edge desktop or enable it in flags.";
      add('assistant', "‚ö†Ô∏è Your browser doesn‚Äôt expose WebGPU. Please try Chrome or Edge on desktop.");
    } else {
      statusEl.textContent = "WebGPU OK ‚Äî preparing‚Ä¶";
      await loadModel(sel.value);
    }

    sel.addEventListener('change', () => loadModel(sel.value));

    form.addEventListener('submit', async (e) => {
      e.preventDefault();
      const q = input.value.trim();
      if (!q || !engine) return;
      add('user', q);
      history.push({ role: 'user', content: q });
      input.value = '';
      setBusy(true);

      try {
        // Streaming reply (token-by-token)
        const stream = await engine.chat.completions.create({
          stream: true,
          messages: [
            { role: 'system', content: 'You are Jarvis, a concise, friendly web assistant.' },
            ...history
          ],
          model: models[sel.value].model_id
        });

        let answer = '';
        let live = document.getElementById('live');
        if (!live) {
          live = document.createElement('div');
          live.id = 'live';
          live.className = 'msg bot';
          live.innerHTML = `<div class="bubble"></div>`;
          chatEl.appendChild(live);
        }
        const bubble = live.querySelector('.bubble');

        for await (const chunk of stream) {
          const delta = chunk?.choices?.[0]?.delta?.content ?? '';
          if (delta) {
            answer += delta;
            bubble.textContent = answer;
            chatEl.scrollTop = chatEl.scrollHeight;
          }
        }
        live.removeAttribute('id'); // finalize
        history.push({ role: 'assistant', content: answer });
      } catch (err) {
        console.error(err);
        add('assistant', '‚ö†Ô∏è Something went wrong while generating the reply.');
      } finally {
        setBusy(false);
        input.focus();
      }
    });
  </script>
</body>
</html>
